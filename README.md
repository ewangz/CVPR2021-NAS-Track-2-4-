# AI-Studio-项目标题
CVPR2021 NAS竞赛Track 2第4名方案

## 项目描述
1.1 比赛介绍
神经架构搜索（NAS）是根据实际硬件条件获取优秀网络的有效方法。众所周知，我们必须消耗大量的计算资源来评估子网络的性能。为了节省计算资源，使用agent任务来预测性能，这带来了预测性能与实际性能之间的差距，因此至今一直困扰着学者们。由于使用代理任务和非代理任务时存在一些相关性，我们可以使用少量非代理任务样本来提高代理任务预测性能。最近可以用GPNAS解决这个问题，但是性能不完善。
另一方面，当数据集很小时，机器学习通常会受到阻碍。提出小样本学习（FSL）来解决这个问题，但 FSL 的核心问题是经验风险最小化器不可靠。然而，小样本学习研究大多集中在深度学习或分类上，很少有解决机器学习回归问题的方法。

1.2 比赛分析
2021 NAS 性能预测挑战赛就考虑了上述问题。挑战使用类似 Mobilenet 的搜索空间，其中 16 个块是可搜索的。每个块有六种不同的操作：三种内核大小选择和两种扩展率选择。

1.3 数据集介绍
提供了两个训练集：stage1 有 200 个不准确的样本，stage2 有 31 个准确的样本。参赛者需要根据两个训练集预测测试集样本的表现，即解决小样本学习问题。

1.4 问题分析
为了解决这个问题，我们首先对其进行了详细的分析。 主要挑战是样本太少。 总共只有231个训练集数据，甚至只有31个是准确的。 很难直接从提供的训练集中获得好的信息。 此外，即使我们利用231个数据来训练一些模型，过拟合问题仍然很严重。 为了从提供的训练集中挖掘潜在信息，并尽可能改善过拟合问题，我们提出了一个基于平台的框架。 它有两个主要部分：信息探索是从给定的数据中找到有用的信息，网络模型架构旨在减少过拟合问题。 它们都具有可扩展性来积累试验的好处。 有了平台，安排得当，我们做的实验越多，得到的结果就越好。

2. 方案亮点
针对"撷取有效信息"及"消除过拟合"两大关键点，我们提出一个平台式的解题框架，采用了分进合击战略，选用了两类完全不同的基础模型为出发点，各自优化到可接受的准确度后再进行模型融合。此外，我们用了五种方法从题目提供的训练集及测试集中撷取出有效的信息，同时在三个维度上去优化过拟合问题。

## 项目结构
```
-README.MD
-NAS_Track2.ipynb
```
## 使用方式
https://aistudio.baidu.com/aistudio/projectdetail/1973471
